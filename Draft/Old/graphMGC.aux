\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{heller2012consistent,szekely2007measuring}
\citation{wasserman1996logit,howard2016understanding,christakis2007spread,christakis2008collective}
\citation{fosdick2015testing}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}}
\newlabel{sec:intro}{{1}{2}{Introduction}{section.1}{}}
\citation{shen2016discovering}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces You may conjecture that organizations with the same type are more likely to collaborate each other at first glance; but there has been a lack of statistical method to test if there exists any significant relationship between network topology and node-specific attributes and if any, which node exerts the most dependency on network.\relax }}{3}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:intro}{{1}{3}{You may conjecture that organizations with the same type are more likely to collaborate each other at first glance; but there has been a lack of statistical method to test if there exists any significant relationship between network topology and node-specific attributes and if any, which node exerts the most dependency on network.\relax }{figure.caption.1}{}}
\citation{szekely2007measuring}
\@writefile{toc}{\contentsline {section}{\numberline {2}Methodology}{4}{section.2}}
\newlabel{sec:method}{{2}{4}{Methodology}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Multiscale Generalized Correlation}{4}{subsection.2.1}}
\citation{szekely2013distance}
\citation{shen2016discovering,heller2012consistent}
\citation{shen2016discovering}
\newlabel{eq:MGC}{{2}{5}{Multiscale Generalized Correlation}{equation.2.2}{}}
\citation{lyons2013distance}
\citation{orbanz2015bayesian}
\newlabel{fig:a}{{2a}{6}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:a}{{a}{6}{\relax }{figure.caption.2}{}}
\newlabel{fig:b}{{2b}{6}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:b}{{b}{6}{\relax }{figure.caption.2}{}}
\newlabel{fig:c}{{2c}{6}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:c}{{c}{6}{\relax }{figure.caption.2}{}}
\newlabel{fig:d}{{2d}{6}{\relax }{figure.caption.2}{}}
\newlabel{sub@fig:d}{{d}{6}{\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Assume that a set of edges follow certain stochastic block model, also depending on the distribution function of nodal attributes $X$ (a), then with some amount of noise we have a realized adjacency matrix and a set of attribute outcomes (b) of which Euclidean distances ((c) $\&$ (d)) are suggested to be used in standard distance-based independence test but neither of them manifests block structures evident in the data generating model.\relax }}{6}{figure.caption.2}}
\newlabel{fig:matrics}{{2}{6}{Assume that a set of edges follow certain stochastic block model, also depending on the distribution function of nodal attributes $X$ (a), then with some amount of noise we have a realized adjacency matrix and a set of attribute outcomes (b) of which Euclidean distances ((c) $\&$ (d)) are suggested to be used in standard distance-based independence test but neither of them manifests block structures evident in the data generating model.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Exchangeable Graph}{6}{subsection.2.2}}
\citation{orbanz2015bayesian,caron2014sparse}
\citation{lovasz2006limits}
\citation{chan2013estimation}
\citation{holland1983stochastic}
\newlabel{exchangeability}{{2.1}{7}{2-array exchangeability}{definition.2.1}{}}
\newlabel{graphon}{{2.2}{7}{graphon}{definition.2.2}{}}
\citation{young2007random}
\citation{veitch2015class}
\citation{veitch2015class}
\citation{caron2014sparse}
\citation{caron2014sparse}
\citation{kallenberg1990exchangeable}
\citation{kallenberg1990exchangeable}
\citation{coifman2006diffusion}
\citation{coifman2006diffusion,lafon2006diffusion}
\newlabel{eq:graphon}{{7}{9}{Exchangeable Graph}{equation.2.7}{}}
\newlabel{point}{{2.3}{9}{Joint exchangeability on point process}{definition.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Family of Network Distances and Test Statistics}{9}{subsection.2.3}}
\newlabel{eq:diffusion}{{9}{10}{Family of Network Distances and Test Statistics}{equation.2.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textit  {Diffusion matrix}, as a proposed alternative for Euclidean distance of $A$, provides \textbf  {one-parameter family of network-based distances} where at early stage, e.g. at $t=1$, distance matrix is very similar to Euclidean distance of $A$ but as time goes by the pattern shown in the distance matrix changes, and \textbf  {at optimal time point $t^{*} = 5$ distance matrix shows most clear block structures and at the same time it exhibits most dependence to distance matrix of $\mathbf  {X}$.}\relax }}{10}{figure.caption.3}}
\newlabel{fig:diffusions}{{3}{10}{\textit {Diffusion matrix}, as a proposed alternative for Euclidean distance of $A$, provides \textbf {one-parameter family of network-based distances} where at early stage, e.g. at $t=1$, distance matrix is very similar to Euclidean distance of $A$ but as time goes by the pattern shown in the distance matrix changes, and \textbf {at optimal time point $t^{*} = 5$ distance matrix shows most clear block structures and at the same time it exhibits most dependence to distance matrix of $\mathbf {X}$.}\relax }{figure.caption.3}{}}
\newlabel{lemma_graphon}{{2.1}{10}{Exchangeability and \textit {i.i.d} of $A$ in graphon}{theorem.2.1}{}}
\newlabel{main_lemma}{{2.2}{11}{Exchangeability and \textit {i.i.d} of $\mathbf {U}_{t}$}{theorem.2.2}{}}
\newlabel{lemma_graphex}{{2.3}{11}{Exchangeability and \textit {i.i.d} of $A$ in graphex}{theorem.2.3}{}}
\citation{szekely2007measuring}
\newlabel{eq:iid}{{10}{12}{Family of Network Distances and Test Statistics}{equation.2.10}{}}
\newlabel{lemma1}{{2.4}{12}{}{theorem.2.4}{}}
\newlabel{lemma2}{{2.5}{12}{}{theorem.2.5}{}}
\newlabel{eq:conv1}{{11}{12}{}{equation.2.11}{}}
\newlabel{eq:conv2}{{12}{12}{}{equation.2.12}{}}
\citation{fosdick2015testing}
\newlabel{theoremMain}{{2.6}{13}{}{equation.2.13}{}}
\newlabel{theorem2}{{2.7}{13}{}{theorem.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Measure for Node Contribution}{13}{subsection.2.4}}
\newlabel{eq:contribution}{{14}{13}{Measure for Node Contribution}{equation.2.14}{}}
\citation{heller2012consistent}
\@writefile{toc}{\contentsline {section}{\numberline {3}Simulation Study}{14}{section.3}}
\newlabel{sec:sim}{{3}{14}{Simulation Study}{section.3}{}}
\newlabel{eq:joint_model}{{15}{14}{Simulation Study}{equation.3.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Stochastic block model}{14}{subsection.3.1}}
\newlabel{SC@1}{{\caption@xref {??}{ on input line 365}}{15}{Stochastic block model}{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces This power heatmap illustrates the superior power of multiscale generalized correlation (\texttt  {MGC}) under diffusion distance matrix (\texttt  {DF}) in three SBM (model\nobreakspace  {}\ref  {eq:Three}), compared to under adjacency matrix distance (\texttt  {Adj}) or latent factor distance (\texttt  {LT}). \textbf  {This demonstrates one exemplary network where \texttt  {MGC} statistic along with a family of diffusion distances catches non monotonic correlations efficiently than the other statistics and metrics.}\relax }}{15}{figure.caption.4}}
\newlabel{fig:threeSBM}{{4}{15}{This power heatmap illustrates the superior power of multiscale generalized correlation (\texttt {MGC}) under diffusion distance matrix (\texttt {DF}) in three SBM (model~\ref {eq:Three}), compared to under adjacency matrix distance (\texttt {Adj}) or latent factor distance (\texttt {LT}). \textbf {This demonstrates one exemplary network where \texttt {MGC} statistic along with a family of diffusion distances catches non monotonic correlations efficiently than the other statistics and metrics.}\relax }{figure.caption.4}{}}
\citation{karrer2011stochastic}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces X-axis of $\theta $ controls the existence/amount of nonlinear dependency and in this particular case nonlinearity exists when $\theta > 0.2$ and gets larger as it increases. You can see the discrepancy in power between global and local scale tests also gets larger accordingly, \textbf  {mostly due to decreasing power of global test but relatively stable power of \texttt  {MGC} under nonlinear dependency} as presented in the left panel.\relax }}{16}{figure.caption.5}}
\newlabel{fig:powerplot}{{5}{16}{X-axis of $\theta $ controls the existence/amount of nonlinear dependency and in this particular case nonlinearity exists when $\theta > 0.2$ and gets larger as it increases. You can see the discrepancy in power between global and local scale tests also gets larger accordingly, \textbf {mostly due to decreasing power of global test but relatively stable power of \texttt {MGC} under nonlinear dependency} as presented in the left panel.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Degree-corrected two block model}{16}{subsection.3.2}}
\citation{hoff2002latent}
\citation{fosdick2015testing}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces (a) In degree-corrected SBM where the variability in degree distribution increases as $\tau $ increases, testing power of diffusion maps are more likely to be robust against increasing variability compared to other network metrics, e.g. adjacency matrix or latent positions. \texttt  {FH} test statistics allowing different dimensions of network factors perform consistently well but still have less power than \texttt  {MGC}. (b) \texttt  {MGC} utilizing diffusion distances loses some power under additive and multiplicative model which favors estimated latent position metrics, but \texttt  {MGC} does as good as \texttt  {FH} tests under latent factor metrics which closes to the truth. This reveals the flexibility in distance-based matrix in \texttt  {MGC} statistics, which can be chosen depending on model fit or preliminary knowledge.\relax }}{17}{figure.caption.6}}
\newlabel{fig:combined}{{6}{17}{(a) In degree-corrected SBM where the variability in degree distribution increases as $\tau $ increases, testing power of diffusion maps are more likely to be robust against increasing variability compared to other network metrics, e.g. adjacency matrix or latent positions. \texttt {FH} test statistics allowing different dimensions of network factors perform consistently well but still have less power than \texttt {MGC}. (b) \texttt {MGC} utilizing diffusion distances loses some power under additive and multiplicative model which favors estimated latent position metrics, but \texttt {MGC} does as good as \texttt {FH} tests under latent factor metrics which closes to the truth. This reveals the flexibility in distance-based matrix in \texttt {MGC} statistics, which can be chosen depending on model fit or preliminary knowledge.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Additive and multiplicative graph model}{17}{subsection.3.3}}
\newlabel{ssec:ame}{{3.3}{17}{Additive and multiplicative graph model}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Node Contribution Test}{18}{subsection.3.4}}
\newlabel{ssec:node}{{3.4}{18}{Node Contribution Test}{subsection.3.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces This plot describes that both power of \texttt  {MGC} and the rate of correctly-ranked node contribution increase as the number of nodes increases when only half of the nodes for each simulation actually are set to be dependent on network, \textbf  {which validates the use of node contribution measure in independence test.}\relax }}{18}{figure.caption.7}}
\newlabel{fig:contribution}{{7}{18}{This plot describes that both power of \texttt {MGC} and the rate of correctly-ranked node contribution increase as the number of nodes increases when only half of the nodes for each simulation actually are set to be dependent on network, \textbf {which validates the use of node contribution measure in independence test.}\relax }{figure.caption.7}{}}
\newlabel{eq:inclusion_rate}{{18}{18}{Node Contribution Test}{equation.3.18}{}}
\citation{ingold2014structural}
\citation{minhas2016inferential}
\citation{cranmer2016navigating}
\citation{cranmer2016navigating}
\citation{ingold2014structural}
\@writefile{toc}{\contentsline {section}{\numberline {4}Real Data Examples}{19}{section.4}}
\newlabel{sec:real}{{4}{19}{Real Data Examples}{section.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Both panels depict the collaborative networks during the two time periods having significant network dependency in types of organizations. \textbf  {Using \texttt  {MGC} statistics, we are not only able to test network independence but also calculate each node's amount of contribution to detecting dependence, which is proportional to node size here.} You can tell that the tendency to collaborate within the same type is strongest among the business group while scientist relatively collaborates less with any others, especially in the first period.\relax }}{19}{figure.caption.8}}
\newlabel{fig:politics}{{8}{19}{Both panels depict the collaborative networks during the two time periods having significant network dependency in types of organizations. \textbf {Using \texttt {MGC} statistics, we are not only able to test network independence but also calculate each node's amount of contribution to detecting dependence, which is proportional to node size here.} You can tell that the tendency to collaborate within the same type is strongest among the business group while scientist relatively collaborates less with any others, especially in the first period.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces In the first period, we have two extreme cases among the business group and science group, which reflects our observations in Figure\nobreakspace  {}\ref  {fig:politics}. Generally organizations cooperate more actively between different types in the second period but still their collaboration network is highly dependent on their organization types.\relax }}{20}{figure.caption.9}}
\newlabel{fig:barplots}{{9}{20}{In the first period, we have two extreme cases among the business group and science group, which reflects our observations in Figure~\ref {fig:politics}. Generally organizations cooperate more actively between different types in the second period but still their collaboration network is highly dependent on their organization types.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussions}{20}{section.5}}
\newlabel{sec:discussion}{{5}{20}{Discussions}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}appendix}{21}{appendix.A}}
\newlabel{sec:appendix}{{A}{21}{appendix}{appendix.A}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}simulation schemes}{21}{subsection.A.1}}
\newlabel{eq:Three}{{19}{21}{simulation schemes}{equation.A.19}{}}
\newlabel{eq:dcVariance}{{20}{22}{simulation schemes}{equation.A.20}{}}
\newlabel{eq:ame}{{21}{22}{simulation schemes}{equation.A.21}{}}
\newlabel{eq:contri}{{22}{22}{simulation schemes}{equation.A.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Algorithms}{23}{subsection.A.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Mutiscale representation of nodes in network\relax }}{23}{algorithm.1}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Multiscale Generalized Correlation (\texttt  {MGC}) test statistics with diffusion maps as a network-based distance.\relax }}{23}{algorithm.2}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Node-specific contribution to detecting dependency via \texttt  {MGC} statistic\relax }}{24}{algorithm.3}}
\citation{coifman2006diffusion,lafon2006diffusion}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}Lemmas and Theorems}{25}{subsection.A.3}}
\newlabel{finetti}{{A.1}{25}{\textit {de Finetti's Theorem}}{theorem.A.1}{}}
\newlabel{Aldous_Hoover}{{A.2}{25}{\textit {Aldous Hoover Theorem}}{theorem.A.2}{}}
\citation{veitch2015class}
\citation{szekely2007measuring}
\citation{szekely2007measuring}
\citation{szekely2007measuring}
\citation{szekely2007measuring}
\citation{shen2016discovering}
\bibstyle{Chicago}
\bibdata{Biblio}
\bibcite{caron2014sparse}{{1}{2014}{{Caron and Fox}}{{Caron and Fox}}}
\newlabel{eq:SLLN}{{34}{29}{Lemmas and Theorems}{equation.A.34}{}}
\bibcite{chan2013estimation}{{2}{2013}{{Chan et~al.}}{{Chan, Costa, and Airoldi}}}
\bibcite{christakis2007spread}{{3}{2007}{{Christakis and Fowler}}{{Christakis and Fowler}}}
\bibcite{christakis2008collective}{{4}{2008}{{Christakis and Fowler}}{{Christakis and Fowler}}}
\bibcite{coifman2006diffusion}{{5}{2006}{{Coifman and Lafon}}{{Coifman and Lafon}}}
\bibcite{cranmer2016navigating}{{6}{2016}{{Cranmer et~al.}}{{Cranmer, Leifeld, McClurg, and Rolfe}}}
\bibcite{fosdick2015testing}{{7}{2015}{{Fosdick and Hoff}}{{Fosdick and Hoff}}}
\bibcite{heller2012consistent}{{8}{2012}{{Heller et~al.}}{{Heller, Heller, and Gorfine}}}
\bibcite{hoff2002latent}{{9}{2002}{{Hoff et~al.}}{{Hoff, Raftery, and Handcock}}}
\bibcite{holland1983stochastic}{{10}{1983}{{Holland et~al.}}{{Holland, Laskey, and Leinhardt}}}
\bibcite{howard2016understanding}{{11}{2016}{{Howard et~al.}}{{Howard, Cox~Pahnke, Boeker, et~al.}}}
\bibcite{ingold2014structural}{{12}{2014}{{Ingold and Leifeld}}{{Ingold and Leifeld}}}
\bibcite{kallenberg1990exchangeable}{{13}{1990}{{Kallenberg}}{{Kallenberg}}}
\bibcite{karrer2011stochastic}{{14}{2011}{{Karrer and Newman}}{{Karrer and Newman}}}
\bibcite{lafon2006diffusion}{{15}{2006}{{Lafon and Lee}}{{Lafon and Lee}}}
\bibcite{lovasz2006limits}{{16}{2006}{{Lov{\'a}sz and Szegedy}}{{Lov{\'a}sz and Szegedy}}}
\bibcite{lyons2013distance}{{17}{2013}{{Lyons et~al.}}{{Lyons et~al.}}}
\bibcite{minhas2016inferential}{{18}{2016}{{Minhas et~al.}}{{Minhas, Hoff, and Ward}}}
\bibcite{orbanz2015bayesian}{{19}{2015}{{Orbanz and Roy}}{{Orbanz and Roy}}}
\bibcite{shen2016discovering}{{20}{2016}{{Shen et~al.}}{{Shen, Priebe, Maggioni, and Vogelstein}}}
\bibcite{szekely2013distance}{{21}{2013}{{Sz{\'e}kely and Rizzo}}{{Sz{\'e}kely and Rizzo}}}
\bibcite{szekely2007measuring}{{22}{2007}{{Sz{\'e}kely et~al.}}{{Sz{\'e}kely, Rizzo, Bakirov, et~al.}}}
\bibcite{veitch2015class}{{23}{2015}{{Veitch and Roy}}{{Veitch and Roy}}}
\bibcite{wasserman1996logit}{{24}{1996}{{Wasserman and Pattison}}{{Wasserman and Pattison}}}
\bibcite{young2007random}{{25}{2007}{{Young and Scheinerman}}{{Young and Scheinerman}}}
